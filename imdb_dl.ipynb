{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWhES6sl4Hn9"
   },
   "source": [
    "Sentiment Analysis of IMDB Dataset using Deep Learning methods.\n",
    "\n",
    "Dataset link: https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GFl-deJQ2p81",
    "outputId": "423323e1-0d06-4151-9d0d-0ec501cb2950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "# importing pandas for data processing, numpy for linear algebra, nltk for natural lang processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "import string\n",
    "from string import punctuation\n",
    "import re\n",
    "# importing lemmatizer stopwords and punctuations\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# importing other keras and sklearn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding,Conv1D,LSTM,GRU,BatchNormalization,Flatten,Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nj_KkPpx4L1I"
   },
   "source": [
    "Getting the dataset from Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TucNZW74CPl",
    "outputId": "21a170f9-4d3c-42f2-9677-efcccb3dfa18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "or1BN-lh4D9M"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"/content/drive/MyDrive/dataset/IMDB_Dataset.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "uOMtjY3D5DRV",
    "outputId": "836e22ec-39ad-4af5-9845-9c22d6ae5b2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49582</td>\n",
       "      <td>49582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Okay, so it starts very unimaginatively with a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>24884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               49582     49582\n",
       "unique                                              49582         2\n",
       "top     Okay, so it starts very unimaginatively with a...  positive\n",
       "freq                                                    1     24884"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Dropping duplicate rows. Verified that duplicate entries are present.\n",
    "df = df.drop_duplicates(subset=['review', 'sentiment'], keep='first')\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rmDnIcKmx1i"
   },
   "source": [
    "Functions for lower- casing, removing punctuation, linebreak tag, concatenated words, emojis, special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxjcKOKm5E0F"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "def sub_lower(text):\n",
    "  # global count\n",
    "  # count = count + 1\n",
    "  # print(count)\n",
    "  text = text.lower() # convert all text to lowercase\n",
    "  text = re.sub(\"<br\\s*/?>\", \" \", text) # remove line breaks\n",
    "   # remove concatenations in english language\n",
    "  text=re.sub(\"isn't\",'is not',text)\n",
    "  text=re.sub(\"he's\",'he is',text)\n",
    "  text=re.sub(\"wasn't\",'was not',text)\n",
    "  text=re.sub(\"there's\",'there is',text)\n",
    "  text=re.sub(\"couldn't\",'could not',text)\n",
    "  text=re.sub(\"won't\",'will not',text)\n",
    "  text=re.sub(\"they're\",'they are',text)\n",
    "  text=re.sub(\"she's\",'she is',text)\n",
    "  text=re.sub(\"there's\",'there is',text)\n",
    "  text=re.sub(\"wouldn't\",'would not',text)\n",
    "  text=re.sub(\"haven't\",'have not',text)\n",
    "  text=re.sub(\"that's\",'that is',text)\n",
    "  text=re.sub(\"you've\",'you have',text)\n",
    "  text=re.sub(\"he's\",'he is',text)\n",
    "  text=re.sub(\"what's\",'what is',text)\n",
    "  text=re.sub(\"weren't\",'were not',text)\n",
    "  text=re.sub(\"we're\",'we are',text)\n",
    "  text=re.sub(\"hasn't\",'has not',text)\n",
    "  text=re.sub(\"you'd\",'you would',text)\n",
    "  text=re.sub(\"shouldn't\",'should not',text)\n",
    "  text=re.sub(\"let's\",'let us',text)\n",
    "  text=re.sub(\"they've\",'they have',text)\n",
    "  text=re.sub(\"you'll\",'you will',text)\n",
    "  text=re.sub(\"i'm\",'i am',text)\n",
    "  text=re.sub(\"we've\",'we have',text)\n",
    "  text=re.sub(\"it's\",'it is',text)\n",
    "  text=re.sub(\"don't\",'do not',text)\n",
    "  text=re.sub(\"that's\",'that is',text)\n",
    "  text=re.sub(\"i'm\",'i am',text)\n",
    "  text=re.sub(\"it's\",'it is',text)\n",
    "  text=re.sub(\"she's\",'she is',text)\n",
    "  text=re.sub(\"he's'\",'he is',text)\n",
    "  text=re.sub(\"i'm\",'i am',text)\n",
    "  text=re.sub(\"i'd\",'i did',text)\n",
    "  text=re.sub(\"he's\",'he is',text)\n",
    "  text=re.sub('there’s','there is',text)\n",
    "  text=re.sub(\"who'll\",'who will',text)\n",
    "  text=re.sub(\"you'll\",'you will',text)\n",
    "  \n",
    "  # special characters, emojis, urls, numbers\n",
    "  text=re.sub('\\x91The','The',text)\n",
    "  text=re.sub('\\x97','',text)\n",
    "  text=re.sub('\\x84The','The',text)\n",
    "  text=re.sub('\\uf0b7','',text)\n",
    "  text=re.sub('¡¨','',text)\n",
    "  text=re.sub('\\x95','',text)\n",
    "  text=re.sub('\\x8ei\\x9eek','',text)\n",
    "  text=re.sub('\\xad','',text)\n",
    "  text=re.sub('\\x84bubble','bubble',text)\n",
    "  text=re.sub(r'http\\S+', '', text)\n",
    "  text=re.sub(r'[0-9]', '', text)\n",
    "\n",
    "  return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ksn_R9CAm3_q"
   },
   "source": [
    "Tokenization, removal of stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kj9k6tdS_DuN"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "def clean_doc(text):\n",
    "  doc = sub_lower(text)\n",
    "  global count\n",
    "  count = count+1\n",
    "  # print(count)\n",
    "  # split into tokens by white space\n",
    "  tokens = doc.split()\n",
    "  # remove punctuation from each token\n",
    "  table = str.maketrans('', '', punctuation)\n",
    "  tokens = [w.translate(table) for w in tokens]\n",
    "  # remove remaining tokens that are not alphabetic\n",
    "  tokens = [word for word in tokens if word.isalpha()]\n",
    "  # filter out stop words\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  tokens = [w for w in tokens if not w in stop_words]\n",
    "  # filter out short tokens\n",
    "  tokens = [word for word in tokens if len(word) > 1]\n",
    "  text = \" \".join(tokens)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JG602pZY5hY5"
   },
   "outputs": [],
   "source": [
    "df[\"review\"]=df.loc[:, \"review\"].apply(clean_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "EW4F3mak_L-g",
    "outputId": "9d526018-5758-4302-9012-cbc2035ff62c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching oz episode ho...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy jake thinks zombie...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one reviewers mentioned watching oz episode ho...  positive\n",
       "1  wonderful little production filming technique ...  positive\n",
       "2  thought wonderful way spend time hot summer we...  positive\n",
       "3  basically family little boy jake thinks zombie...  negative\n",
       "4  petter matteis love time money visually stunni...  positive"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjiPE4FtnCGp"
   },
   "source": [
    "One hot encoding the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUlpknoE-jSn"
   },
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "df['sentiment']= le.fit_transform(df['sentiment'])\n",
    "labels=to_categorical(df['sentiment'],num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eoZ4EE1NJyle",
    "outputId": "85a7f2d7-38f6-4432-a419-0137cd6e0e4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "_FPmUnqs_bJ1",
    "outputId": "e40c23bb-f8ad-401f-fe43-f4c079519f1c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching oz episode ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy jake thinks zombie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one reviewers mentioned watching oz episode ho...          1\n",
       "1  wonderful little production filming technique ...          1\n",
       "2  thought wonderful way spend time hot summer we...          1\n",
       "3  basically family little boy jake thinks zombie...          0\n",
       "4  petter matteis love time money visually stunni...          1"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPbAfbHsnJqW"
   },
   "source": [
    "Tokenizing the corpus of text. ~47k words appear more than twice but empirically 10k performs better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGYtMY34AUOe"
   },
   "outputs": [],
   "source": [
    "num_words = 10000 # number of words that occur more than 2 times is around 47k\n",
    "tokenizer=Tokenizer(num_words=num_words,oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df['review'])\n",
    "word_index=tokenizer.word_index\n",
    "total_vocab=len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sDhrJnTvAgxc",
    "outputId": "c7920c73-219d-4dc8-f3b7-17d2c7fc08b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161952\n"
     ]
    }
   ],
   "source": [
    "print(total_vocab)\n",
    "# print(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cPjw9tknZhE"
   },
   "source": [
    "Padding and converting text to sequence of numbers in vocabulary. Train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8IuVZhiqAm1G"
   },
   "outputs": [],
   "source": [
    "max_len = 400 # 75% reviews are 100 % covered with length of 281\n",
    "embeddings=256\n",
    "sequences = tokenizer.texts_to_sequences(df['review'])\n",
    "sequences_padded=pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Z6rX0dCD5V4"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(sequences_padded,labels,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YDPA1rAnsDX"
   },
   "source": [
    "Defining the model. Including dropouts and regularizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbYx7kVrzdZ4"
   },
   "outputs": [],
   "source": [
    "model= keras.Sequential()\n",
    "model.add(Embedding(num_words,embeddings,input_length=max_len))\n",
    "model.add(Conv1D(256,10,activation='relu'))\n",
    "model.add(keras.layers.Bidirectional(LSTM(128,return_sequences=True)))\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "model.add(LSTM(64))\n",
    "model.add(keras.layers.Dropout(0.4))\n",
    "model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRiKXkLjERhW",
    "outputId": "5ec1a044-6cb6-49c5-87bb-fab3ac109740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 400, 128)          1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 391, 256)          327936    \n",
      "_________________________________________________________________\n",
      "bidirectional_18 (Bidirectio (None, 391, 256)          394240    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 391, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 64)                82176     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 2,084,482\n",
      "Trainable params: 2,084,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model= keras.Sequential()\n",
    "# model.add(Embedding(num_words,embeddings,input_length=max_len))\n",
    "# model.add(Conv1D(256,10,activation='relu'))\n",
    "# model.add(keras.layers.Bidirectional(LSTM(128,return_sequences=True,kernel_regularizer=tf.keras.regularizers.l1(0.01),activity_regularizer=tf.keras.regularizers.l2(0.01))))\n",
    "# model.add(LSTM(64))\n",
    "# model.add(keras.layers.Dropout(0.4))\n",
    "# model.add(Dense(2,activation='softmax'))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HLqmORlXQvaV"
   },
   "outputs": [],
   "source": [
    "# model.add(Embedding(num_words,embeddings,input_length=max_len))\n",
    "# model.add(Conv1D(256,10,activation='relu'))\n",
    "# model.add(keras.layers.Bidirectional(LSTM(128,return_sequences=True)))\n",
    "# model.add(LSTM(64))\n",
    "# model.add(keras.layers.Dropout(0.4))\n",
    "# model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvDBYn2fFY-e"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']\n",
    "             ) \n",
    "#adamax provides slight improvement over adam but increase in training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4V3xIxR8Fx5F",
    "outputId": "e492e87c-4e88-4def-8fa8-56d410dc0090"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "310/310 [==============================] - 130s 402ms/step - loss: 0.4532 - accuracy: 0.7701\n",
      "Epoch 2/4\n",
      "310/310 [==============================] - 124s 402ms/step - loss: 0.2403 - accuracy: 0.9102\n",
      "Epoch 3/4\n",
      "310/310 [==============================] - 125s 402ms/step - loss: 0.1364 - accuracy: 0.9527\n",
      "Epoch 4/4\n",
      "310/310 [==============================] - 125s 402ms/step - loss: 0.0945 - accuracy: 0.9698\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,epochs=4, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AcidDMwsF_Ev",
    "outputId": "b3228c1f-7373-4ece-d474-4fbb1733eb23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.49%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=10)\n",
    "# print(scores)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sk88i7EBIeBv"
   },
   "outputs": [],
   "source": [
    "model.save('imdb_model1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14UeUP-ygWDM"
   },
   "source": [
    "5 epochs\n",
    "85.1\n",
    "3 epochs - saved as imdb_model1\n",
    "88.7\n",
    "adding removing bi-gru and bi-lstm layers\n",
    "87 ish\n",
    "\n",
    "---\n",
    "\n",
    "10k tokens\n",
    "87.51\n",
    "adding regularizer\n",
    "88.10\n",
    "48k\n",
    "87.00\n",
    "\n",
    "---\n",
    "\n",
    "adamax\n",
    "87.6\n",
    "adam\n",
    "87.4\n",
    "\n",
    "---\n",
    "adding more layers\n",
    "87.48\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "imdb_dl_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
